{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUi6bEVcEw6f",
        "outputId": "ac8adceb-7810-492d-a3f5-c66fdc3d77a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ON5YFjkenPI",
        "outputId": "d89abac8-e250-4f71-f28b-479ded1da538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn1KfrGSEz1V",
        "outputId": "fc587025-e65f-4908-b02a-305c324ca7ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model as model_loader\n",
        "import joblib\n",
        "\n",
        "\n",
        "\n",
        "model = None\n",
        "\n",
        "def load_model():\n",
        "    try:\n",
        "        model = model_loader(\"/content/CRNNSpoof_Model.h5\")\n",
        "        return model\n",
        "    except FileNotFoundError:\n",
        "        st.sidebar.error(\"Model file not found. Please make sure the file exists.\")\n",
        "        return None\n",
        "\n",
        "model = load_model()\n",
        "st.sidebar.success(\"Model loaded!\")\n",
        "\n",
        "\n",
        "st.title(\"Voice authentication 🎵:\")\n",
        "audio_file = None\n",
        "audio_file = st.file_uploader(\"Upload Audio\", type=[\"wav\",\"mp3\",\"flac\"])\n",
        "\n",
        "st.sidebar.header(\"Play the audio\")\n",
        "st.sidebar.audio(audio_file)\n",
        "\n",
        "\n",
        "# Function to extract features from an audio file\n",
        "def extract_features(file_path, segment_length):\n",
        "    try:\n",
        "        # Load the audio file\n",
        "        y, sr = librosa.load(file_path)\n",
        "        # Calculate the number of segments based on the segment length and audio length\n",
        "        num_segments = int(np.ceil(len(y) / float(segment_length * sr)))\n",
        "        print(\"num_segments: \"+ str(num_segments))\n",
        "        # Initialize a list to store the features for this file\n",
        "        features = []\n",
        "\n",
        "        # Extract features for each segment\n",
        "        for i in range(num_segments):\n",
        "            # Calculate start and end frame for the current segment\n",
        "            start_frame = i * segment_length * sr\n",
        "            end_frame = min(len(y), (i + 1) * segment_length * sr)\n",
        "            # Extract audio for this segment\n",
        "            y_segment = y[start_frame:end_frame]\n",
        "\n",
        "            # Extract features\n",
        "            chroma_stft = np.mean(librosa.feature.chroma_stft(y=y_segment, sr=sr))\n",
        "            rms = np.mean(librosa.feature.rms(y=y_segment))\n",
        "            spec_cent = np.mean(librosa.feature.spectral_centroid(y=y_segment, sr=sr))\n",
        "            spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y_segment, sr=sr))\n",
        "            rolloff = np.mean(librosa.feature.spectral_rolloff(y=y_segment, sr=sr))\n",
        "            zcr = np.mean(librosa.feature.zero_crossing_rate(y_segment))\n",
        "            mfccs = librosa.feature.mfcc(y=y_segment, sr=sr)\n",
        "            mfccs_mean = np.mean(mfccs, axis=1)\n",
        "\n",
        "            # Append the extracted features to the list\n",
        "            features.append([chroma_stft, rms, spec_cent, spec_bw, rolloff, zcr, *mfccs_mean])\n",
        "\n",
        "        return np.array(features)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def make_prediction(features):\n",
        "    output = model.predict(features)\n",
        "    return [1 if value >= 0.5 else 0 for value in output]\n",
        "\n",
        "\n",
        "if st.sidebar.button(\"Test Audio\"):\n",
        "  if audio_file is not None:\n",
        "    st.sidebar.success(\"Processing audio...\")\n",
        "\n",
        "    features = extract_features(audio_file, segment_length=1)\n",
        "    X = pd.DataFrame(features, columns = ['chroma_stft', 'rms', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20'])\n",
        "    scaler = joblib.load(\"/content/CRNNSpoof_scale.joblib\")\n",
        "\n",
        "    X_test_scaled = scaler.transform(features.reshape(features.shape[0], -1))\n",
        "    X_test_scaled = X_test_scaled.reshape(features.shape)\n",
        "\n",
        "    X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "\n",
        "    # Use the model to make predictions on the dataset\n",
        "    st.write(\"Making predictions with the model...\")\n",
        "\n",
        "    if features is not None:\n",
        "        prediction_result = make_prediction(X_test_scaled)\n",
        "\n",
        "    if np.average(prediction_result) <= 0.5:\n",
        "      st.write(\"Prediction: Fake \")\n",
        "    else:\n",
        "      st.write(\"Prediction: Real \")\n",
        "  else:\n",
        "    st.sidebar.warning(\"No Model\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLvhEVW6E6II"
      },
      "outputs": [],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukboCngRFpoH"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4DK8joaBE9Ot"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15rBWVT5FCAA"
      },
      "outputs": [],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}